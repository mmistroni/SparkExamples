# Configuration for a Spark pull-based app

#Declare
a1.sources = src
a1.sinks = spark
a1.channels = chs

#Define Source
a1.sources.src.type = spooldir
a1.sources.src.spoolDir= c:/spooldir2

#Define Sink
a1.sinks.spark.type = org.apache.spark.streaming.flume.sink.SparkSink
a1.sinks.spark.hostname = localhost
a1.sinks.spark.port = 9988
a1.sinks.spark.channel = chs
a1.sinks.spark.rollSize = 10000000
a1.sinks.spark.poolSize = 10000


#Define Channels
a1.channels.chs.type = memory
a1.channels.c1.capacity = 100000000
a1.channels.c1.transactionCapacity = 80000
a1.channels.c1.keep-alive = 30

#Tie Source and Sink to Channel
a1.sources.src.channels = chs
a1.sinks.spark.channel = chs


# Command to launch flume:bin\flume-ng agent -n a1 -f conf/spark-sink.conf -property "flume.root.logger=INFO,console"