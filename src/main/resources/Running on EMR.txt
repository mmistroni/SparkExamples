-- Create Cluster



-- file and examples are available from this bucket
  ec2-bucket-mm-spark\master.idx.2017.q1

-- to copy data to s3 use this command

aws s3 cp ./spark-examples.jar s3://ec2-bucket-mm-spark


-- copy jar and master file from bucket to EMR

aws s3 cp s3://ec2-bucket-mm-spark/spark-examples.jar .


aws s3 cp s3://ec2-bucket-mm-spark/run_on_emr.sh .



spark-submit --master yarn --deploy-mode cluster 

spark submit options

--packages org.apache.hadoop:hadoop-aws:2.7.1 
--class edgar.EdgarFilingReaderTaskNoPipeline  

-- application args

s3a://ec2-bucket-mm-spark/master.idx.2017.q1  4  0.003 hdfs://ip-172-31-29-97.us-west-2.compute.internal:8020/tmp/form4-results-cluster3.9.results


# save on hdfs. sa mple here https://stackoverflow.com/questions/40069264/how-can-i-save-an-rdd-into-hdfs-and-later-read-it-back

## get the URL of the hadoop server using this command
# https://stackoverflow.com/questions/26216876/find-port-number-where-hdfs-is-listening

[hadoop@ip-172-31-29-97 ~]$ hdfs getconf -confKey fs.default.name
18/09/03 20:42:03 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
hdfs://ip-172-31-29-97.us-west-2.compute.internal:8020

hdfs://ip-172-31-29-97.us-west-2.compute.internal:8020/tmp/form4-results-cluster3.9.results


S3Path:s3a://ec2-bucket-mm-spark/form4-results-cluster16.8.results.hdfs


Step Type: Custom JAR
Name: S3DistCP
JAR Location: /usr/lib/hadoop/hadoop-distcp.jar
DISTCP arguments
s3-dist-cp –s3Endpoint=s3.amazonaws.com –dest=s3://edgar-ml-bucket –src=/tmp-res –srcPattern=.*[a-zA-Z,]+

alternatively
hadoop distcp hdfs://ip-172-31-29-97.us-west-2.compute.internal:8020/tmp/form4-results-cluster3.9.results  s3://edgar-ml-bucket ==> notworking. cannot find hdfs instance

aws s3 cp /tmp/form4-results-cluster17.8.results s3://edgar-ml-bucket/tmp/form4-results-cluster17.8.results


// here's link on how to copy
https://myawsjourney.wordpress.com/2018/02/14/how-to-move-a-file-from-s3-to-hdfs-with-s3distcp/

// here's a link on s3distcp 
http://dmitrypukhov.pro/s3-dist-cp-is-missing-in-emr-4/#more-675
--- To store on HDFS

https://github.com/awsdocs/amazon-emr-release-guide/blob/master/doc_source/emr-3x-s3distcp.md

use Path /tmp/form4-results.16.8.hdfs




-- to try: 
1 - deploy on cluster
2 - go back to  app based only on one scala module and see how it behaves
3 - consistently be able to read informations from edgar

-- instructions on how to run on EMR are here

https://stackoverflow.com/questions/43424540/submit-a-spark-application-via-aws-emr

    
    
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  